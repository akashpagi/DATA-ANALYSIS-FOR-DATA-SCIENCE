{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3943784a-06da-459d-8321-26db1e8fad55",
   "metadata": {},
   "source": [
    "#### **S27.7 - WEB SCRAPING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390aa43-881d-47d6-8463-eada3c8b1890",
   "metadata": {},
   "source": [
    "**What is Web Scraping?**\n",
    "- Web scraping is an automated method to obtain large amounts of data from websites.\n",
    "- Data obtained is often unstructured HTML format, converted into structured data for various applications.\n",
    "- Methods include online services, API usage, or creating custom code for scraping.\n",
    "- Some large websites provide APIs for structured data access, but not all sites do.\n",
    "- Web scraping involves a crawler (AI algorithm) and a scraper (specific tool) for data extraction.\n",
    "- The crawler browses the web, searching for specific data by following links.\n",
    "- The scraper is designed based on project complexity to accurately extract required data.\n",
    "\n",
    "\n",
    "**How  Web Scrapers Work ?**\n",
    "- Web scrapers can extract either all data or specific data from websites based on user preferences.\n",
    "- It's advisable to specify desired data to streamline the scraping process.\n",
    "- For example, extracting only juicer model data from an Amazon page, excluding customer reviews.\n",
    "- The scraping process involves providing URLs, loading HTML code (and possibly CSS/JavaScript) from those sites.\n",
    "- The scraper then extracts the required data from the HTML code.\n",
    "- Output format is user-specified, commonly Excel spreadsheet, CSV file, or JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e084c4d-7422-45b4-8f7a-905a57154713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84437188-4592-4fd6-91f7-156dd62d0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a Fake User Agent - https://www.zenrows.com/blog/user-agent-web-scraping#avoid-blocking\n",
    "headers = {\"User-Agent\": \"User-Agent Received: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
    "webpage = requests.get('https://www.ambitionbox.com/list-of-companies?page=1', headers=headers).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa8ace1-c7c4-4110-be0b-eec866d52708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lxml is the default in bs4, assuming you have lxml installed. So unless you happen to be working with BeautifulSoup3\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848fc7f4-4a01-44af-be5b-ed3f7b65b1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['71.9k Reviews',\n",
       " '854.1k Salaries',\n",
       " '5.9k Interviews',\n",
       " '626 Jobs',\n",
       " '11.4k Benefits',\n",
       " '78 Photos',\n",
       " '45.5k Reviews',\n",
       " '583.2k Salaries',\n",
       " '4.1k Interviews',\n",
       " '4k Jobs',\n",
       " '7k Benefits',\n",
       " '39 Photos',\n",
       " '41k Reviews',\n",
       " '559.4k Salaries',\n",
       " '3.5k Interviews',\n",
       " '656 Jobs',\n",
       " '5.8k Benefits',\n",
       " '62 Photos',\n",
       " '36.4k Reviews',\n",
       " '414.6k Salaries',\n",
       " '3.4k Interviews',\n",
       " '315 Jobs',\n",
       " '4.9k Benefits',\n",
       " '73 Photos',\n",
       " '33.3k Reviews',\n",
       " '131.6k Salaries',\n",
       " '1.5k Interviews',\n",
       " '247 Jobs',\n",
       " '3.2k Benefits',\n",
       " '30 Photos',\n",
       " '33k Reviews',\n",
       " '143.9k Salaries',\n",
       " '1.8k Interviews',\n",
       " '215 Jobs',\n",
       " '3.7k Benefits',\n",
       " '39 Photos',\n",
       " '31.2k Reviews',\n",
       " '463.3k Salaries',\n",
       " '4.6k Interviews',\n",
       " '914 Jobs',\n",
       " '5.1k Benefits',\n",
       " '84 Photos',\n",
       " '29.1k Reviews',\n",
       " '372.1k Salaries',\n",
       " '2.4k Interviews',\n",
       " '668 Jobs',\n",
       " '3.9k Benefits',\n",
       " '28 Photos',\n",
       " '27.9k Reviews',\n",
       " '290.1k Salaries',\n",
       " '2.4k Interviews',\n",
       " '493 Jobs',\n",
       " '4.1k Benefits',\n",
       " '35 Photos',\n",
       " '27.1k Reviews',\n",
       " '251.9k Salaries',\n",
       " '2.3k Interviews',\n",
       " '1k Jobs',\n",
       " '3.6k Benefits',\n",
       " '42 Photos',\n",
       " '25.7k Reviews',\n",
       " '189.6k Salaries',\n",
       " '1.9k Interviews',\n",
       " '532 Jobs',\n",
       " '3.6k Benefits',\n",
       " '32 Photos',\n",
       " '21.7k Reviews',\n",
       " '98.4k Salaries',\n",
       " '1.1k Interviews',\n",
       " '320 Jobs',\n",
       " '2.2k Benefits',\n",
       " '41 Photos',\n",
       " '21.4k Reviews',\n",
       " '105k Salaries',\n",
       " '1k Interviews',\n",
       " '136 Jobs',\n",
       " '3.3k Benefits',\n",
       " '30 Photos',\n",
       " '20.5k Reviews',\n",
       " '75.8k Salaries',\n",
       " '1.1k Interviews',\n",
       " '283 Jobs',\n",
       " '2k Benefits',\n",
       " '22 Photos',\n",
       " '20.4k Reviews',\n",
       " '142.4k Salaries',\n",
       " '3.3k Interviews',\n",
       " '706 Jobs',\n",
       " '4.2k Benefits',\n",
       " '47 Photos',\n",
       " '20.3k Reviews',\n",
       " '67.8k Salaries',\n",
       " '1.2k Interviews',\n",
       " '131 Jobs',\n",
       " '2.6k Benefits',\n",
       " '40 Photos',\n",
       " '19.4k Reviews',\n",
       " '223.9k Salaries',\n",
       " '1.4k Interviews',\n",
       " '2.2k Jobs',\n",
       " '2.7k Benefits',\n",
       " '16 Photos',\n",
       " '18.5k Reviews',\n",
       " '79.3k Salaries',\n",
       " '1k Interviews',\n",
       " '139 Jobs',\n",
       " '2.9k Benefits',\n",
       " '30 Photos',\n",
       " '18.4k Reviews',\n",
       " '58.9k Salaries',\n",
       " '1.1k Interviews',\n",
       " '241 Jobs',\n",
       " '2k Benefits',\n",
       " '89 Photos',\n",
       " '17.8k Reviews',\n",
       " '50.1k Salaries',\n",
       " '567 Interviews',\n",
       " '46 Jobs',\n",
       " '1.5k Benefits',\n",
       " '29 Photos']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_elements = soup.find_all('a', {'class': 'companyCardWrapper__ActionWrapper'})\n",
    "rev_count_list = [element.text.strip() for element in rev_elements]\n",
    "all_reviews_concatenated = ' '.join(rev_count_list)\n",
    "\n",
    "# Print the concatenated string and the list\n",
    "rev_count_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1156668f-0e0b-45dc-b0a5-7ee9d8391995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Counts List: ['71.9k', '42.5k']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_content = '''\n",
    "<div class=\"companyCardWrapper__primaryInformation\">\n",
    "  <a target=\"_blank\" href=\"https://www.ambitionbox.com/reviews/tcs-reviews\" class=\"companyCardWrapper__ActionWrapper\">\n",
    "    <span class=\"companyCardWrapper__ActionCount\">71.9k</span>\n",
    "    <span class=\"companyCardWrapper__ActionTitle\">Reviews</span>\n",
    "  </a>\n",
    "</div>\n",
    "<div class=\"companyCardWrapper__primaryInformation\">\n",
    "  <a target=\"_blank\" href=\"https://www.example.com\" class=\"companyCardWrapper__ActionWrapper\">\n",
    "    <span class=\"companyCardWrapper__ActionCount\">42.5k</span>\n",
    "    <span class=\"companyCardWrapper__ActionTitle\">Reviews</span>\n",
    "  </a>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all elements with class 'companyCardWrapper__primaryInformation'\n",
    "company_elements = soup.find_all('div', class_='companyCardWrapper__primaryInformation')\n",
    "\n",
    "# Create an empty list to store review counts\n",
    "review_counts = []\n",
    "\n",
    "# Extract the review counts and append to the list using nested find\n",
    "for company_element in company_elements:\n",
    "    # Find the 'a' element with class 'companyCardWrapper__ActionWrapper' within the current 'div'\n",
    "    action_wrapper = company_element.find('a', class_='companyCardWrapper__ActionWrapper')\n",
    "    \n",
    "    # If 'a' element is found, find the 'span' element with class 'companyCardWrapper__ActionCount' within it\n",
    "    if action_wrapper:\n",
    "        review_count_element = action_wrapper.find('span', class_='companyCardWrapper__ActionCount')\n",
    "        \n",
    "        # If 'span' element is found, extract the text and append to the list\n",
    "        if review_count_element:\n",
    "            review_count = review_count_element.text.strip()\n",
    "            review_counts.append(review_count)\n",
    "\n",
    "print(\"Review Counts List:\", review_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b09804-dbfe-407e-9037-dd2eaa93fb2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m rating \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m company:\n\u001b[1;32m---> 15\u001b[0m     names\u001b[38;5;241m.\u001b[39mappend(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m     16\u001b[0m     sectors\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompanyCardWrapper__interLinking\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     17\u001b[0m     emp_counts\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompanyCardWrapper__interLinking\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# Code for scarping single page\n",
    "company = soup.find_all('div', {'class': 'companyCardWrapper__primaryInformation'})\n",
    "\n",
    "# Find all elements with class 'companyCardWrapper__primaryInformation'\n",
    "company_elements = soup.find_all('div', class_='companyCardWrapper__primaryInformation')\n",
    "\n",
    "names = []\n",
    "sectors = []\n",
    "review_counts = []\n",
    "emp_counts = []\n",
    "company_type = []\n",
    "rating = []\n",
    "\n",
    "for i in company:\n",
    "    names.append(i.find('h2').text.strip())\n",
    "    sectors.append(i.find_all('span', class_ = 'companyCardWrapper__interLinking')[0].text.strip().split('|')[0])\n",
    "    emp_counts.append(i.find_all('span', class_ = 'companyCardWrapper__interLinking')[0].text.strip().split('|')[1])\n",
    "    company_type.append(i.find_all('span', class_ = 'companyCardWrapper__interLinking')[0].text.strip().split('|')[2])\n",
    "    rating.append(i.find('span', class_ = 'companyCardWrapper__companyRatingValue').text.strip())\n",
    "    #no_of_reviews.append(i.find_all('span', class_='companyCardWrapper__ActionCount').text.strip()[element.text.strip() for element in rev_elements])\n",
    "    # Use list comprehension to extract review counts\n",
    "    #no_of_reviews.append([element.text.strip() for element in i.select('div.companyCardWrapper__primaryInformation a.companyCardWrapper__ActionCount')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8d39b9-e5eb-4cb9-bbbd-691e6135b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4869a1d-75a7-4b18-a36d-ccf22e827cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Set a Fake User Agent - https://www.zenrows.com/blog/user-agent-web-scraping#avoid-blocking\n",
    "headers = {\"User-Agent\": \"User-Agent Received: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
    "webpage = requests.get('https://www.ambitionbox.com/list-of-companies?page=1', headers=headers).text\n",
    "\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "\n",
    "\n",
    "# Find all elements with the class 'companyCardWrapper__ActionCount' within 'a' tags\n",
    "company = soup.find_all(attrs=[{'class':'companyCardWrapper__tertiaryInformation', 'class':'companyCardWrapper__primaryInformation' }])\n",
    "\n",
    "# Create an empty list to store review counts\n",
    "review_counts = []\n",
    "\n",
    "# Extract the review counts and append to the list\n",
    "for i in company:\n",
    "    review_count_element = i.find('span', class_='companyCardWrapper__ActionCount')\n",
    "    \n",
    "    if review_count_element:\n",
    "        review_count = review_count_element.text.strip()\n",
    "        review_counts.append(review_count)\n",
    "\n",
    "review_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86f9d110-af31-4f05-84cb-57a019307ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set a Fake User Agent - https://www.zenrows.com/blog/user-agent-web-scraping#avoid-blocking\n",
    "headers = {\"User-Agent\": \"User-Agent Received: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
    "webpage = requests.get('https://www.ambitionbox.com/list-of-companies?page=1', headers=headers).text\n",
    "\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "\n",
    "\n",
    "# Use list comprehension to extract review counts\n",
    "review = [element.text.strip() for element in soup.select('div.companyCardWrapper__primaryInformation span.companyCardWrapper__ActionCount')]\n",
    "\n",
    "review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76dc8bb-a753-448b-a19f-1793438d3f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306bd1e6-3ae1-4982-9cf1-800488376f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2a38f-cfeb-42a2-af5d-73cbf247e2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
